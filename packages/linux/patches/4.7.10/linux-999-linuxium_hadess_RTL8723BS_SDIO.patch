diff -Naur linux-4.8.7.orig/drivers/mmc/host/sdhci-acpi.c linux-4.8.7/drivers/mmc/host/sdhci-acpi.c
--- linux-4.8.7.orig/drivers/mmc/host/sdhci-acpi.c	2016-11-14 15:55:38.109615388 +0800
+++ linux-4.8.7/drivers/mmc/host/sdhci-acpi.c	2016-11-14 16:03:03.337052684 +0800
@@ -49,6 +49,25 @@
 
 #include "sdhci.h"
 
+#ifdef CONFIG_X86
+#include <asm/cpu_device_id.h>
+static bool sdhci_acpi_on_byt(void)
+{
+	static const struct x86_cpu_id byt[] = {
+		{ X86_VENDOR_INTEL, 6, 0x37 },
+		{}
+	};
+
+	return x86_match_cpu(byt);
+}
+#else
+static bool sdhci_acpi_on_byt(void)
+{
+	return false;
+}
+#endif
+
+
 enum {
 	SDHCI_ACPI_SD_CD		= BIT(0),
 	SDHCI_ACPI_RUNTIME_PM		= BIT(1),
@@ -212,6 +231,13 @@
 
 	return ret;
 }
+static void sdhci_acpi_int_dma_latency(struct sdhci_host *host)
+{
+	if (sdhci_acpi_on_byt()) {
+		host->dma_latency = 20;
+		host->lat_cancel_delay = 275;
+	}
+}
 
 static int sdhci_acpi_emmc_probe_slot(struct platform_device *pdev,
 				      const char *hid, const char *uid)
@@ -231,6 +257,8 @@
 	    sdhci_readl(host, SDHCI_CAPABILITIES_1) == 0x00000807)
 		host->timeout_clk = 1000; /* 1000 kHz i.e. 1 MHz */
 
+	sdhci_acpi_int_dma_latency(host);
+
 	return 0;
 }
 
@@ -245,6 +273,8 @@
 
 	host = c->host;
 
+	sdhci_acpi_int_dma_latency(host);
+
 	/* Platform specific code during sdio probe slot goes here */
 
 	return 0;
@@ -261,6 +291,8 @@
 
 	host = c->host;
 
+	sdhci_acpi_int_dma_latency(host);
+
 	/* Platform specific code during sd probe slot goes here */
 
 	if (hid && !strcmp(hid, "80865ACA")) {
diff -Naur linux-4.8.7.orig/drivers/mmc/host/sdhci.c linux-4.8.7/drivers/mmc/host/sdhci.c
--- linux-4.8.7.orig/drivers/mmc/host/sdhci.c	2016-11-14 15:55:38.117611388 +0800
+++ linux-4.8.7/drivers/mmc/host/sdhci.c	2016-11-14 16:14:25.959463212 +0800
@@ -748,6 +748,45 @@
 	}
 }
 
+static bool sdhci_pm_qos_use_dma_latency(struct sdhci_host *host)
+{
+return host->dma_latency != PM_QOS_DEFAULT_VALUE;
+}
+
+static void sdhci_pm_qos_set_dma_latency(struct sdhci_host *host,
+					 struct mmc_request *mrq)
+{
+	if (sdhci_pm_qos_use_dma_latency(host) && mrq->data &&
+	    (host->flags & (SDHCI_USE_SDMA | SDHCI_USE_ADMA))) {
+		pm_qos_update_request(&host->pm_qos_req, host->dma_latency);
+		host->pm_qos_set = true;
+	}
+}
+
+static void sdhci_pm_qos_unset(struct sdhci_host *host)
+{
+	unsigned int delay;
+
+	if (host->pm_qos_set) {
+		host->pm_qos_set = false;
+		delay = host->consecutive_req ? host->lat_cancel_delay : 0;
+		pm_qos_cancel_request_lazy(&host->pm_qos_req, delay);
+	}
+}
+
+static void sdhci_pm_qos_add(struct sdhci_host *host)
+{
+	if (sdhci_pm_qos_use_dma_latency(host))
+		pm_qos_add_request(&host->pm_qos_req, PM_QOS_CPU_DMA_LATENCY,
+				   PM_QOS_DEFAULT_VALUE);
+}
+
+static void sdhci_pm_qos_remove(struct sdhci_host *host)
+{
+	if (pm_qos_request_active(&host->pm_qos_req))
+		pm_qos_remove_request(&host->pm_qos_req);
+}
+
 static void sdhci_prepare_data(struct sdhci_host *host, struct mmc_command *cmd)
 {
 	u8 ctrl;
@@ -1471,6 +1510,8 @@
 
 	host = mmc_priv(mmc);
 
+	sdhci_pm_qos_set_dma_latency(host, mrq);
+
 	/* Firstly check card presence */
 	present = mmc->ops->get_cd(mmc);
 
@@ -1489,6 +1530,8 @@
 		}
 	}
 
+	host->consecutive_req = 0;
+
 	if (!present || host->flags & SDHCI_DEVICE_DEAD) {
 		mrq->cmd->error = -ENOMEDIUM;
 		sdhci_finish_mrq(host, mrq);
@@ -2182,8 +2225,13 @@
 {
 	struct sdhci_host *host = mmc_priv(mmc);
 
-	mrq->data->host_cookie = COOKIE_UNMAPPED;
+	host->consecutive_req = 1;
 
+	if (mrq->data->host_cookie) {
+		mrq->data->host_cookie = COOKIE_UNMAPPED;
+		return;
+	}
+	
 	if (host->flags & SDHCI_REQ_USE_DMA)
 		sdhci_pre_dma_transfer(host, mrq->data, COOKIE_PRE_MAPPED);
 }
@@ -2265,6 +2313,8 @@
 	struct mmc_request *mrq;
 	int i;
 
+	sdhci_pm_qos_unset(host);
+
 	spin_lock_irqsave(&host->lock, flags);
 
 	for (i = 0; i < SDHCI_MAX_MRQS; i++) {
@@ -2941,6 +2991,8 @@
 	host = mmc_priv(mmc);
 	host->mmc = mmc;
 	host->mmc_host_ops = sdhci_ops;
+	host->dma_latency = PM_QOS_DEFAULT_VALUE;
+
 	mmc->ops = &host->mmc_host_ops;
 
 	host->flags = SDHCI_SIGNALING_330;
@@ -3492,6 +3544,8 @@
 	 */
 	mmc->max_blk_count = (host->quirks & SDHCI_QUIRK_NO_MULTIBLOCK) ? 1 : 65535;
 
+	sdhci_pm_qos_add(host);
+
 	return 0;
 
 unreg:
@@ -3572,6 +3626,7 @@
 	free_irq(host->irq, host);
 untasklet:
 	tasklet_kill(&host->finish_tasklet);
+	sdhci_pm_qos_remove(host);
 
 	if (!IS_ERR(mmc->supply.vqmmc))
 		regulator_disable(mmc->supply.vqmmc);
@@ -3646,6 +3701,8 @@
 
 	host->adma_table = NULL;
 	host->align_buffer = NULL;
+
+	sdhci_pm_qos_remove(host);
 }
 
 EXPORT_SYMBOL_GPL(sdhci_remove_host);
diff -Naur linux-4.8.7.orig/drivers/mmc/host/sdhci.h linux-4.8.7/drivers/mmc/host/sdhci.h
--- linux-4.8.7.orig/drivers/mmc/host/sdhci.h	2016-11-14 15:55:38.117611388 +0800
+++ linux-4.8.7/drivers/mmc/host/sdhci.h	2016-11-14 16:16:51.043556381 +0800
@@ -19,6 +19,7 @@
 #include <linux/io.h>
 
 #include <linux/mmc/host.h>
+#include <linux/pm_qos.h>
 
 /*
  * Controller registers
@@ -433,6 +434,12 @@
 	struct mmc_host_ops mmc_host_ops;	/* MMC host ops */
 	u64 dma_mask;		/* custom DMA mask */
 
+	struct pm_qos_request pm_qos_req;
+	int dma_latency;
+	int lat_cancel_delay;
+	int consecutive_req;
+	bool pm_qos_set;
+
 #if IS_ENABLED(CONFIG_LEDS_CLASS)
 	struct led_classdev led;	/* LED control */
 	char led_name[32];
diff -Naur linux-4.8.7.orig/include/linux/pm_qos.h linux-4.8.7/include/linux/pm_qos.h
--- linux-4.8.7.orig/include/linux/pm_qos.h	2016-11-14 15:56:14.739290343 +0800
+++ linux-4.8.7/include/linux/pm_qos.h	2016-11-14 16:18:52.355552920 +0800
@@ -126,6 +126,8 @@
 			   s32 new_value);
 void pm_qos_update_request_timeout(struct pm_qos_request *req,
 				   s32 new_value, unsigned long timeout_us);
+void pm_qos_cancel_request_lazy(struct pm_qos_request *req,
+				unsigned int timeout_us);
 void pm_qos_remove_request(struct pm_qos_request *req);
 
 int pm_qos_request(int pm_qos_class);
diff -Naur linux-4.8.7.orig/kernel/power/qos.c linux-4.8.7/kernel/power/qos.c
--- linux-4.8.7.orig/kernel/power/qos.c	2016-11-14 15:56:18.457430236 +0800
+++ linux-4.8.7/kernel/power/qos.c	2016-11-14 16:21:10.497294980 +0800
@@ -526,6 +526,26 @@
 }
 
 /**
+ * pm_qos_cancel_request_lazy - cancels an existing qos request lazily.
+ * @req : handle to list element holding a pm_qos request to use
+ * @timeout_us: the delay before cancelling this qos request in usecs.
+ *
+ * After timeout_us, this qos request is cancelled.
+ */
+void pm_qos_cancel_request_lazy(struct pm_qos_request *req,
+				unsigned int timeout_us)
+{
+	if (!req)
+		return;
+	if (WARN(!pm_qos_request_active(req),
+		 "%s called for unknown object.", __func__))
+		return;
+
+	schedule_delayed_work(&req->work, usecs_to_jiffies(timeout_us));
+}
+EXPORT_SYMBOL_GPL(pm_qos_cancel_request_lazy);
+
+/**
  * pm_qos_remove_request - modifies an existing qos request
  * @req: handle to request list element
  *
